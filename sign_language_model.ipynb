{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 8313\n",
      "Validation samples: 2253\n",
      "Test samples: 1414\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(base_path):\n",
    "    data = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    labels = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "\n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"Warning: Split path {split_path} not found.\")\n",
    "            continue\n",
    "\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "\n",
    "            for file in os.listdir(label_path):\n",
    "                if file.endswith(\".npz\"):\n",
    "                    file_path = os.path.join(label_path, file)\n",
    "\n",
    "                    try:\n",
    "                        # Load the npz file\n",
    "                        keypoints = np.load(file_path)[\"keypoints\"]\n",
    "                        data[split].append(keypoints)\n",
    "                        labels[split].append(label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading file {file_path}: {e}\")\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Usage\n",
    "base_path = \"video_key_points\"\n",
    "data, labels = load_data(base_path)\n",
    "\n",
    "# Accessing data\n",
    "X_train, y_train = data[\"train\"], labels[\"train\"]\n",
    "X_val, y_val = data[\"val\"], labels[\"val\"]\n",
    "X_test, y_test = data[\"test\"], labels[\"test\"]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in y_val not in y_train: {'meaning', 'post'}\n",
      "Labels in y_test not in y_train: {'meaning', 'post'}\n"
     ]
    }
   ],
   "source": [
    "missing_labels_in_train = set(y_val) - set(y_train)\n",
    "print(f\"Labels in y_val not in y_train: {missing_labels_in_train}\")\n",
    "\n",
    "missing_labels_in_train = set(y_test) - set(y_train)\n",
    "print(f\"Labels in y_test not in y_train: {missing_labels_in_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: idx for idx, label in enumerate(sorted(set(y_train)))}\n",
    "for label in y_val:\n",
    "    if label not in label_map:\n",
    "        label_map[label] = len(label_map)\n",
    "\n",
    "for label in y_test:\n",
    "    if label not in label_map:\n",
    "        label_map[label] = len(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = [label_map[label] for label in y_train]\n",
    "y_val_encoded = [label_map[label] for label in y_val]\n",
    "y_test_encoded = [label_map[label] for label in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(label_map)\n",
    "y_train = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val_encoded, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_encoded, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Pad sequences\n",
    "MAX_SEQ_LENGTH = 50  # Example value; set based on your data\n",
    "INPUT_DIM = X_train[0].shape[1]  # Example, assuming uniform feature dimension\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQ_LENGTH, padding='post', dtype='float32')\n",
    "X_val = pad_sequences(X_val, maxlen=MAX_SEQ_LENGTH, padding='post', dtype='float32')\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQ_LENGTH, padding='post', dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to 3D\n",
    "X_train = X_train.reshape(-1, MAX_SEQ_LENGTH, INPUT_DIM)\n",
    "X_val = X_val.reshape(-1, MAX_SEQ_LENGTH, INPUT_DIM)\n",
    "X_test = X_test.reshape(-1, MAX_SEQ_LENGTH, INPUT_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# callbacks = [\n",
    "#     ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss'),\n",
    "#     EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# ]\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     callbacks=callbacks\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pad sequences to ensure equal length\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# MAX_SEQ_LENGTH = 30  # Define max sequence length\n",
    "# INPUT_DIM = data[0].shape[1] if len(data) > 0 else 0  # Dimensionality of keypoints\n",
    "\n",
    "# data_padded = pad_sequences(data, maxlen=MAX_SEQ_LENGTH, dtype=\"float32\", padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# # One-hot encode labels\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# labels_categorical = to_categorical(labels, num_classes=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Masking(mask_value=0.0, input_shape=(MAX_SEQ_LENGTH, INPUT_DIM)),\n",
    "    LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_map), activation='softmax')  # Output layer with one node per class\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_train, y_train, batch_size=32)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
