{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468 * 3)\n",
    "    left_hand = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    right_hand = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    return np.concatenate([pose, face, left_hand, right_hand])\n",
    "\n",
    "def load_missing_video_ids(missing_file):\n",
    "    with open(missing_file, 'r') as f:\n",
    "        missing_ids = {line.strip() for line in f}\n",
    "    return missing_ids\n",
    "\n",
    "def process_metadata(metadata_file, video_base_path, save_base_path, missing_ids, frame_skip=2):\n",
    "    start_time = time.time() \n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    total_videos = 11980  \n",
    "    processed_videos = 0\n",
    "\n",
    "    for entry in metadata:\n",
    "        gloss = entry['gloss']\n",
    "        for instance in entry['instances']:\n",
    "            split = instance['split']\n",
    "            video_id = instance['video_id']\n",
    "\n",
    "            \n",
    "            if video_id in missing_ids:\n",
    "                print(f\"Skipping missing video: {video_id}\")\n",
    "                continue\n",
    "\n",
    "            video_file = os.path.join(video_base_path, f\"{video_id}.mp4\")\n",
    "\n",
    "            # Ensure video exists\n",
    "            if not os.path.exists(video_file):\n",
    "                print(f\"Video not found: {video_file}\")\n",
    "                continue\n",
    "\n",
    "            \n",
    "            save_dir = os.path.join(save_base_path, split, gloss)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            # Process video and extract keypoints\n",
    "            keypoints = []\n",
    "            cap = cv2.VideoCapture(video_file)\n",
    "            with mp_holistic.Holistic(\n",
    "                static_image_mode=False, \n",
    "                min_detection_confidence=0.5, \n",
    "                min_tracking_confidence=0.5,\n",
    "                model_complexity=2,  \n",
    "                enable_segmentation=True  \n",
    "            ) as holistic:\n",
    "                frame_count = 0  \n",
    "\n",
    "                while cap.isOpened():\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    \n",
    "                    frame_count += 1\n",
    "                    \n",
    "                    if frame_count % frame_skip != 0:\n",
    "                        continue\n",
    "\n",
    "                    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    image.flags.writeable = False\n",
    "\n",
    "                    results = holistic.process(image)\n",
    "\n",
    "                    keypoint = extract_keypoints(results)\n",
    "                    keypoints.append(keypoint)\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            np.savez_compressed(os.path.join(save_dir, f\"{video_id}.npz\"), keypoints=np.array(keypoints))\n",
    "\n",
    "            processed_videos += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            # Log progress\n",
    "            print(f\"Processed {processed_videos}/{total_videos} videos: {video_id}.npz\")\n",
    "            print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Processing complete! Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"Total videos processed: {processed_videos}/{total_videos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "metadata_file = \"WLASL_v0.3.json\"\n",
    "video_base_path = \"videos\"\n",
    "save_base_path = \"video_key_points\"\n",
    "missing_file = \"wlasl_class_list.txt\"\n",
    "\n",
    "missing_ids = load_missing_video_ids(missing_file)\n",
    "process_metadata(metadata_file, video_base_path, save_base_path, missing_ids, frame_skip=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
